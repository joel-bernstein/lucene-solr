= Text Analysis and Term Vectors
// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

The section of user guide describes how to perform text analysis and create tf-idf terms vector using
the math expressions.

== Text Analysis

The `analyze` function applies a Solr analyzer to a block of text and returns an array that contains the tokens
emitted by the analyzer. Any analyzer chain attached to a field in Solr's schema can be used with the `analyze`
function.

In the example below, "hello world" is analyzed using the analyzer chain attached to the *subject* field in
the schema. The *subject* field is defined as the field type *text_general*. The text is analyzed using the
analysis chain configured for the *text_general* field type.

[source,text]
----
analyze("hello world", subject)
----

When this expression is sent to the /stream handler it
responds with:

[source,json]
----
{
  "result-set": {
    "docs": [
      {
        "return-value": [
          "hello",
          "world"
        ]
      },
      {
        "EOF": true,
        "RESPONSE_TIME": 0
      }
    ]
  }
}
----

== Annotating Documents

The `analyze` function can be used inside of a `select` function to annotate documents with the tokens
generated by the analysis.

The example below is performing a `search` in collection1. Each tuple returned by the `search`
contains an *id* and *subject*. For each tuple, the
`select` function is selecting the *id* field and calling the `analyze` function on the *subject* field.
The analyzer chain specified by the *subject_bigram* is configured to perform a bigram analysis.
The tokens generated by the `analyze` function are added to each tuple in a field called `terms`.

Notice that the bigram terms have been added to the tuples.

[source,text]
----
select(search(collection1, q="*:*", fl="id, subject", sort="id asc"),
       id,
       analyze(subject, subject_bigram) as terms)
----

When this expression is sent to the /stream handler it
responds with:

[source,json]
----
{
  "result-set": {
    "docs": [
      {
        "terms": [
          "text analysis",
          "analysis example"
        ],
        "id": "1"
      },
      {
        "terms": [
          "example number",
          "number two"
        ],
        "id": "2"
      },
      {
        "EOF": true,
        "RESPONSE_TIME": 4
      }
    ]
  }
}
----

== Term Vectors

The `termVectors` function can be used to build tf-idf
term vectors from terms generated by the `analyze` function.


[source,text]
----
let(a=select(search(collection1, q="*:*", fl="id, subject", sort="id asc"),
             id,
             analyze(subject, subject_bigram) as terms),
    b=termVectors(a))
----

When this expression is sent to the /stream handler it
responds with:

[source,json]
----
{
  "result-set": {
    "docs": [
      {
        "terms": [
          "text analysis",
          "analysis example"
        ],
        "id": "1"
      },
      {
        "terms": [
          "example number",
          "number two"
        ],
        "id": "2"
      },
      {
        "EOF": true,
        "RESPONSE_TIME": 4
      }
    ]
  }
}
----




